{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc9f2be0-b74a-40b8-8684-6d8778e8915f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Join, Transform, and Standardize Data\n",
    "This script loads in the Google data and other city- and country-level variables.\n",
    "\n",
    "Most of the code here deals with missing observations, standardizing the data to account for missing modes or in/outbound data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443229c-7712-45f6-8514-64391a2d1d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2817a4-60a8-40b0-9fc9-7f540d52dedf",
   "metadata": {},
   "source": [
    "### Process city-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5189fbc-d256-4d1d-9081-58b0cb640383",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2023\n",
    "\n",
    "# load in google data, which should be in a subfolder called EIE_data_raw\n",
    "# for access, see the Data Availability statement in the published paper\n",
    "features = pd.read_csv(\"../../EIE_data_raw/features.csv\",usecols=['feature_id','city','state','country','centroid','population'])\n",
    "transport = pd.read_csv(\"../../EIE_data_raw/transport.csv\")\n",
    "\n",
    "# modes are cycling, walking, automobile, and motorcycle (extra modes are transit modes - bus, rail, tram, subway, and ferry)\n",
    "# for most of the analysis, the denominator excludes the extra_modes\n",
    "modes_of_transportation = ['automobile','motorcycle','cycling','on_foot']\n",
    "extra_modes = ['bus','ferry','rail','subway','tram']\n",
    "\n",
    "# auto km and bus km are in terms of vehicle miles and vehicle trips, so convert these to passenger\n",
    "# these are google defaults for the globe. \n",
    "for mode, occupancy in zip(['automobile','bus'],[1.7, 9.9]):\n",
    "    for bound in ['in','out','intra']:\n",
    "        for m in ['trips','full_distance_km']:\n",
    "            transport[f'{mode}_{bound}bound_{m}'] = transport[f'{mode}_{bound}bound_{m}'] * occupancy\n",
    "\n",
    "# determine level of completeness\n",
    "for mode in modes_of_transportation:\n",
    "    missing_inbound_outbound = ((transport[f'{mode}_inbound_trips'].isnull()) | (transport[f'{mode}_outbound_trips'].isnull())) & (transport[f'{mode}_intrabound_trips'].notnull())\n",
    "    missing_intrabound = (transport[f'{mode}_inbound_trips'].notnull()) & (transport[f'{mode}_outbound_trips'].notnull()) & (transport[f'{mode}_intrabound_trips'].isnull())\n",
    "    complete = (transport[f'{mode}_inbound_trips'].notnull()) & (transport[f'{mode}_outbound_trips'].notnull()) & (transport[f'{mode}_intrabound_trips'].notnull())\n",
    "    transport[f'{mode}_completeness'] = np.where(missing_inbound_outbound, 'missing in/bound outbound', (np.where(missing_intrabound, 'missing intrabound', np.where(complete, 'complete','no data'))))\n",
    "\n",
    "# calculate total trips per mode\n",
    "# In- and out-bound trips are weighted at 50%. See the published paper\n",
    "for mode in modes_of_transportation:\n",
    "    transport[f'{mode}_inbound_trips_adj']=transport[f'{mode}_inbound_trips']/2\n",
    "    transport[f'{mode}_outbound_trips_adj']=transport[f'{mode}_outbound_trips']/2\n",
    "    transport[mode+'_total_trips']=transport[[f'{mode}_intrabound_trips',\n",
    "                                              f'{mode}_inbound_trips_adj',f'{mode}_outbound_trips_adj']].sum(axis=1)\n",
    "\n",
    "# calculate total trips across our chosen denominator (no bus, rail, tram, subway, ferry)\n",
    "transport['total_trips'] = transport[[f'{mode}_total_trips' for mode in modes_of_transportation]].sum(axis=1)\n",
    "transport['intrabound_trips'] = transport[[f'{mode}_intrabound_trips' for mode in modes_of_transportation]].sum(axis=1)\n",
    "\n",
    "# drop places with literally no trips\n",
    "transport=transport[transport.total_trips>0]\n",
    "\n",
    "# calculate percentages, and fill in missing intrabound\n",
    "transport.cycling_intrabound_trips = transport.cycling_intrabound_trips.fillna(0)\n",
    "transport.motorcycle_intrabound_trips = transport.motorcycle_intrabound_trips.fillna(0)\n",
    "\n",
    "for mode in modes_of_transportation:\n",
    "    transport[f'tripshare_{mode}_total']=transport.apply(lambda x: x[f'{mode}_total_trips']/x['total_trips'],axis=1)\n",
    "    transport[f'tripshare_{mode}_intrabound']=transport.apply(lambda x: x[f'{mode}_intrabound_trips']/x['intrabound_trips'] if x['intrabound_trips']>0 else 0,axis=1)\n",
    "\n",
    "# determine which modeshare basis will be used for modeshare calculations\n",
    "full_trips=transport.apply(lambda x: True if (x['automobile_completeness'] == 'complete' and x['on_foot_completeness'] == 'complete') else False, axis=1)\n",
    "intrabound_only=transport.apply(lambda x: True if ((x['automobile_completeness'] == 'missing in/bound outbound' or x['automobile_completeness'] == 'complete') & (x['on_foot_completeness'] == 'missing in/bound outbound' or x['on_foot_completeness'] == 'complete')) else False, axis=1)\n",
    "transport['modeshare_basis'] = np.where(full_trips, 'full_trips', (np.where(intrabound_only, 'intrabound_only', 'drop')))\n",
    "\n",
    "# drop places that don't even have complete intrabound data\n",
    "transport=transport[transport['modeshare_basis']!='drop']\n",
    "\n",
    "for index, row in transport.iterrows():\n",
    "    if row['modeshare_basis'] == 'full_trips':\n",
    "        transport.at[index, 'tripshare_cycling'] = row['tripshare_cycling_total']\n",
    "        transport.at[index, 'tripshare_on_foot'] = row['tripshare_on_foot_total'] \n",
    "    elif row['modeshare_basis'] == 'intrabound_only':\n",
    "        transport.at[index, 'tripshare_cycling'] = row['tripshare_cycling_intrabound']\n",
    "        transport.at[index, 'tripshare_on_foot'] = row['tripshare_on_foot_intrabound']\n",
    "\n",
    "transport[\"tripshare_bikewalk\"] = transport[\"tripshare_cycling\"] + transport[\"tripshare_on_foot\"]\n",
    "\n",
    "# this creates columns that stores either all_trips or intrabound_trips based on modeshare_basis\n",
    "mask = transport.modeshare_basis == 'intrabound_only' \n",
    "for mode in modes_of_transportation:\n",
    "    transport[f'trips_{mode}_touse']=transport[f'{mode}_total_trips']\n",
    "    transport.loc[mask, f'trips_{mode}_touse']=transport[f'{mode}_intrabound_trips']\n",
    "\n",
    "# create column of distance in km for all modes (including transit)\n",
    "transport.cycling_intrabound_full_distance_km = transport.cycling_intrabound_full_distance_km.fillna(0)\n",
    "transport.motorcycle_intrabound_full_distance_km =transport.motorcycle_intrabound_full_distance_km.fillna(0)\n",
    "for mode in modes_of_transportation+extra_modes:\n",
    "    # distance\n",
    "    transport[f'km_{mode}']=transport[f'{mode}_intrabound_full_distance_km'].fillna(0)\n",
    "    transport[f'km_{mode}']+=transport[f'{mode}_inbound_full_distance_km'].fillna(0) * 0.5\n",
    "    transport[f'km_{mode}']+=transport[f'{mode}_outbound_full_distance_km'].fillna(0) * 0.5\n",
    "    # just use intrabound for some cities\n",
    "    transport.loc[mask, f'km_{mode}']=transport[f'{mode}_intrabound_full_distance_km'].fillna(0)\n",
    "    \n",
    "# for mode share maps, add in public transport\n",
    "transport['intrabound_trips_allmodes'] = transport['intrabound_trips']\n",
    "transport['trips_total_touse']=transport['total_trips']\n",
    "for mode in extra_modes:\n",
    "    transport['trips_total_touse']+=transport[mode+'_intrabound_trips'].fillna(0)\n",
    "    transport['trips_total_touse']+=transport[mode+'_inbound_trips'].fillna(0)*0.5\n",
    "    transport['trips_total_touse']+=transport[mode+'_outbound_trips'].fillna(0)*0.5\n",
    "    transport['intrabound_trips_allmodes']+=transport[mode+'_intrabound_trips'].fillna(0)\n",
    "    \n",
    "# calculate km\n",
    "transport.loc[mask, 'trips_total_touse']=transport['intrabound_trips_allmodes']\n",
    "km_cols = ['km_'+mode for mode in modes_of_transportation+extra_modes]\n",
    "transport['km_total'] = transport[km_cols].sum(axis=1)\n",
    "\n",
    "# calculate total km on transit modes\n",
    "km_cols_transit = ['km_'+mode for mode in extra_modes]\n",
    "transport['km_transit'] = transport[km_cols_transit].sum(axis=1)\n",
    "\n",
    "# create column of km-share for just main modes (i.e., no transit)\n",
    "km_share_cols = ['km_'+mode for mode in modes_of_transportation]\n",
    "transport['km_no_transit'] = transport[km_share_cols].sum(axis=1)\n",
    "for mode in modes_of_transportation:\n",
    "    transport[f'km_share_{mode}']=transport[f'km_{mode}']/transport['km_total']\n",
    "    transport[f'km_share_{mode}_no_transit']=transport[f'km_{mode}']/transport['km_no_transit']\n",
    "\n",
    "\n",
    "# create df of modeshare for year\n",
    "dfs = {}\n",
    "dfs[f'transport_{year}']=transport[transport.year==year][['feature_id','modeshare_basis','tripshare_cycling','tripshare_on_foot','tripshare_bikewalk',\n",
    "                                                'trips_automobile_touse', 'km_automobile','km_share_automobile','km_share_automobile_no_transit',\n",
    "                                                'trips_motorcycle_touse', 'km_motorcycle','km_share_motorcycle','km_share_motorcycle_no_transit',\n",
    "                                                'trips_cycling_touse', 'km_cycling','km_share_cycling','km_share_cycling_no_transit',\n",
    "                                                'trips_on_foot_touse', 'km_on_foot','km_share_on_foot','km_share_on_foot_no_transit',\n",
    "                                                'km_bus','km_ferry', 'km_rail','km_subway','km_tram','km_transit',\n",
    "                                                'trips_total_touse','km_total','km_no_transit']].copy()\n",
    "dfs[f'transport_{year}'].rename(columns={'tripshare_cycling':f'tripshare_cycling_{str(year)[2:]}','tripshare_on_foot':f'tripshare_on_foot_{str(year)[2:]}','tripshare_bikewalk':f'tripshare_bikewalk_{str(year)[2:]}'},inplace=True)\n",
    "\n",
    "# turn modeshare tag into a boolean integer\n",
    "dfs[f'transport_{year}'].modeshare_basis=dfs[f'transport_{year}'].modeshare_basis.str.replace('intrabound_only','0').replace('full_trips','1')\n",
    "dfs[f'transport_{year}'].rename(columns={'modeshare_basis':'includes_inboundoutbound'},inplace=True)\n",
    "dfs[f'transport_{year}'].includes_inboundoutbound=dfs[f'transport_{year}'].includes_inboundoutbound.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2617ed6-0797-4c9b-9ff0-5f7ce42c075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in whether there were any trips on high-capacity transit (rail/subway/tram) in year\n",
    "hc_transit=transport.copy()\n",
    "hc_transit=hc_transit[hc_transit.year==year]\n",
    "transit_modes=['rail','subway','tram']\n",
    "transit_col=[mode+'_inbound_trips' for mode in transit_modes]+[mode+'_outbound_trips' for mode in transit_modes]+[\n",
    "    mode+'_intrabound_trips' for mode in transit_modes]\n",
    "hc_transit['hc_transit_trips']=hc_transit[transit_col].sum(axis=1)\n",
    "hc_transit['rail_in_city']=hc_transit['hc_transit_trips'].apply(lambda x: 1 if x>0 else 0)\n",
    "hc_transit['rail_in_city']=hc_transit['rail_in_city'].astype('int64')\n",
    "\n",
    "dfs[f'transport_{year}']=dfs[f'transport_{year}'].set_index('feature_id').join(hc_transit.set_index('feature_id')[['rail_in_city']]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7202a-e0f0-4fd3-a092-d8f1f819b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join together all city-level data\n",
    "# these data files are in the git repository\n",
    "climate_metrics=pd.read_csv(\"data/climate_metrics.csv\").drop(columns=['Unnamed: 0'])\n",
    "street_metrics=pd.read_csv(\"data/street_metrics.tsv\",sep='\\t')\n",
    "overlapped=pd.read_csv(\"data/polygon_matches.csv\").drop(columns=['Unnamed: 0']) # used to drop cities where our boundaries do not match\n",
    "dfs['data_'+str(year)[2:]]=features.set_index('feature_id').join(dfs[f'transport_{year}'].set_index('feature_id')).join(climate_metrics.set_index('feature_id')).join(\n",
    "    street_metrics.set_index('feature_id')).join(overlapped.set_index('feature_id')).reset_index()\n",
    "\n",
    "# drop anything with null values (places with no boundary at all or no bike/ped data for that year) or where the polygons don't match\n",
    "dfs['data_'+str(year)[2:]]=dfs['data_'+str(year)[2:]].dropna(subset=['bikelane_length_km','mway_length_km','roads_km','slope','wt_density','sndi','sndi_difference'])\n",
    "dfs['data_'+str(year)[2:]]=dfs['data_'+str(year)[2:]].dropna(subset=[f'tripshare_bikewalk_{str(year)[2:]}'])\n",
    "dfs['data_'+str(year)[2:]]=dfs['data_'+str(year)[2:]][dfs['data_'+str(year)[2:]].contained!=True]\n",
    "\n",
    "# keep only cities with a population > 0\n",
    "dfs['data_'+str(year)[2:]]=dfs['data_'+str(year)[2:]][dfs['data_'+str(year)[2:]].population>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c089a8-ac41-4b11-92c3-723266d0f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate bikelanes per km of roads\n",
    "dfs['data_'+str(year)[2:]]['bikelane_per_road_km']=dfs['data_'+str(year)[2:]].bikelane_length_km/dfs['data_'+str(year)[2:]].roads_km\n",
    "dfs['data_'+str(year)[2:]]['mway_per_road_km']=dfs['data_'+str(year)[2:]].mway_length_km/dfs['data_'+str(year)[2:]].roads_km\n",
    "\n",
    "# calculate sndi (sndi_difference with floor of 0)\n",
    "dfs['data_'+str(year)[2:]]['sndi_added']=dfs['data_'+str(year)[2:]].sndi_difference.apply(lambda x: x if x>0 else 0)\n",
    "\n",
    "# log transform right-skew data\n",
    "dfs['data_'+str(year)[2:]]['ln_population']=dfs['data_'+str(year)[2:]].population.apply(lambda x: np.log(x))\n",
    "dfs['data_'+str(year)[2:]]['ln_sndi']=dfs['data_'+str(year)[2:]].sndi.apply(lambda x: np.log(x+1))\n",
    "dfs['data_'+str(year)[2:]]['ln_wt_density']=dfs['data_'+str(year)[2:]].wt_density.apply(lambda x: np.log(x+1))\n",
    "dfs['data_'+str(year)[2:]]['ln_slope']=dfs['data_'+str(year)[2:]].slope.apply(lambda x: np.log(x))\n",
    "dfs['data_'+str(year)[2:]]['ln_sndi_added']=dfs['data_'+str(year)[2:]].sndi_added.apply(lambda x: np.log(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ba4c9-e78c-4685-9f32-0a1b9b3d9df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary that maps core variable name to column name from original dataset\n",
    "city_var_dict={'sndi':'ln_sndi','density':'ln_wt_density','precip':'ln_total_precipitation','min_temp':'min_temp',\n",
    "               'max_temp':'max_temp','bikelanes':'bikelane_per_road_km','motorways':'mway_per_road_km','slope':'ln_slope',\n",
    "               'sndi_added':'ln_sndi_added','population':'ln_population'}\n",
    "\n",
    "# created dataframe of scaled x-variables\n",
    "df_scaled=pd.DataFrame(preprocessing.scale(dfs['data_'+str(year)[2:]][[value for value in city_var_dict.values()]]),\n",
    "                       columns=[key+'_standard' for key in city_var_dict.keys()],index=dfs['data_'+str(year)[2:]].index)\n",
    "\n",
    "# create square values of temperature data and density (for polynomial relationship to dependent)\n",
    "df_scaled['min_temp_standard2']=df_scaled['min_temp_standard']**2\n",
    "df_scaled['max_temp_standard2']=df_scaled['max_temp_standard']**2\n",
    "df_scaled['density_standard2']=df_scaled['density_standard']**2\n",
    "\n",
    "# reverse the direction of sndi (so that it measures connectedness instead of disconnectedness)\n",
    "df_scaled['sndi_standard']=-df_scaled['sndi_standard']\n",
    "\n",
    "dfs['data_'+str(year)[2:]] = pd.concat([dfs['data_'+str(year)[2:]], df_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63cdd07-1615-47ca-9b02-ef4e657d0246",
   "metadata": {},
   "source": [
    "### Process country-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83df21d-9b37-4bec-9592-876afdc9dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df with list of countries\n",
    "country_data = pd.DataFrame(dfs['data_'+str(year)[2:]].sort_values('country').country.unique(), columns = ['country'])\n",
    "\n",
    "country_data['country_num'] = country_data.index\n",
    "\n",
    "# drop \"N/A\" result of cities in places not assigned a country (e.g. in Kashmir)\n",
    "country_data=country_data.dropna(subset=['country']) \n",
    "\n",
    "# open WDI data and clean up names so will join to google names\n",
    "wdi=pd.read_csv('data/wdi.csv')\n",
    "name_dict={'Brunei Darussalam':'Brunei',\n",
    "           'Curacao':'Curaçao',\n",
    "           \"Cote d'Ivoire\":\"Côte d'Ivoire\",\n",
    "           \"Congo, Dem. Rep.\":\"Democratic Republic of the Congo\",\n",
    "           \"Egypt, Arab Rep.\":\"Egypt\",\n",
    "           \"Iran, Islamic Rep.\":\"Iran\",\n",
    "           \"Kyrgyz Republic\":\"Kyrgyzstan\",\n",
    "           \"Lao PDR\":\"Laos\",\n",
    "           \"Myanmar\":\"Myanmar (Burma)\",\n",
    "           \"Congo, Rep.\":\"Republic of the Congo\",\n",
    "           \"Slovak Republic\":\"Slovakia\",\n",
    "           \"Syrian Arab Republic\":\"Syria\",\n",
    "           \"Bahamas, The\":\"The Bahamas\",\n",
    "           \"Gambia, The\":\"The Gambia\",\n",
    "           \"Turkiye\":\"Turkey\",\n",
    "           \"Venezuela, RB\":\"Venezuela\",\n",
    "           \"Yemen, Rep.\":\"Yemen\"}\n",
    "wdi['country']=wdi['Country Name'].replace(name_dict)\n",
    "\n",
    "# transform numeric data to be numeric\n",
    "numeric_cols = [col for col in wdi.columns.to_list() if col.endswith(']')]\n",
    "for col in numeric_cols:\n",
    "    wdi[col] = pd.to_numeric(wdi[col], errors='coerce')\n",
    "\n",
    "# find the most recent value for each metric\n",
    "wdi['most_recent_value']=wdi.apply(lambda x: x['2022 [YR2022]'],axis=1)\n",
    "for y in [2021,2020,2019,2018]:\n",
    "    wdi['most_recent_value']=wdi.apply(lambda x: x.most_recent_value if x.most_recent_value >=0 else x[f'{y} [YR{y}]'], axis=1)\n",
    "\n",
    "# pivot to transform dataset from one row per variable to one row per country with variable's most recent value\n",
    "wdi_country=pd.pivot_table(wdi,index='country',values='most_recent_value',columns='Series Code',aggfunc='first').reset_index()\n",
    "\n",
    "# do join \n",
    "country_data=country_data.set_index('country').join(wdi_country.set_index('country'),how='left').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59990703-9f29-4ec4-8537-2992c97717a6",
   "metadata": {},
   "source": [
    "Semi-manual process of filling in missing data that are missing from the WDI data or that correspond to a geography that does not correspond well to the WDI geographies before joining this data to the city-level data.\n",
    "* The Google EIE data treats French oversees departments (French Guiana, Guadeloupe, Martinique, and Réunion) as their own countries, while the WDI data only report on these geographies as being part of France. Given that the characteristics of the oversees departments differ substantially from mainland France, we used data from Insee (the French National Institute for Statistics and Economic Studies) to [calculate adjustment factors](https://docs.google.com/spreadsheets/d/1id_FmPEmkoihhck7v55YmwrFKaGzNShf/edit?usp=drive_link&ouid=110519951430869187067&rtpof=true&sd=true) for each oversees department, and then estimated department-level values by applying these adjustment factors to the most recently available WDI data for France. [Regional GDP per capita](https://www.insee.fr/fr/statistiques/5020211) were used to adjust GDP per capita, and [base population statistics](https://www.insee.fr/fr/statistiques/2521169) were used to adjust the dependency ratio (with this [Territory Comparator](https://www.insee.fr/fr/statistiques/1405599?geo=REG-01+REG-02+REG-03+REG-04) used to identify the regional codes associated with each oversees department). New Caledonia was assigned average oversees department values.\n",
    "* Other missing data were replaced based on regional averages (e.g. data for Venezuela were substituted with data for the \"Latin America & Carribean\" region and data for Taiwan were substituted with data for the \"East Asia & Pacific\" region)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32fd97-3171-40a2-a021-1942bfca3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace data for France.\n",
    "france_gdp={'French Guiana':0.423098983*country_data[country_data.country=='France']['NY.GDP.PCAP.KD'].iloc[0],\n",
    "                 'Guadeloupe':0.635527723*country_data[country_data.country=='France']['NY.GDP.PCAP.KD'].iloc[0],\n",
    "                 'Martinique':0.693928145*country_data[country_data.country=='France']['NY.GDP.PCAP.KD'].iloc[0],\n",
    "                 'Réunion':0.634817101*country_data[country_data.country=='France']['NY.GDP.PCAP.KD'].iloc[0],\n",
    "                 'New Caledonia':0.567267473*country_data[country_data.country=='France']['NY.GDP.PCAP.KD'].iloc[0]}\n",
    "france_dep={'French Guiana':1.018224798*country_data[country_data.country=='France']['SP.POP.DPND'].iloc[0],\n",
    "                 'Guadeloupe':0.987761253*country_data[country_data.country=='France']['SP.POP.DPND'].iloc[0],\n",
    "                 'Martinique':0.973945071*country_data[country_data.country=='France']['SP.POP.DPND'].iloc[0],\n",
    "                 'Réunion':0.867912461*country_data[country_data.country=='France']['SP.POP.DPND'].iloc[0],\n",
    "                 'New Caledonia':0.933531615*country_data[country_data.country=='France']['SP.POP.DPND'].iloc[0]}\n",
    "for key,value in france_gdp.items():\n",
    "    country_data.loc[country_data.country==key, 'NY.GDP.PCAP.KD'] = value    \n",
    "for key,value in france_dep.items():\n",
    "    country_data.loc[country_data.country==key, 'SP.POP.DPND'] = value\n",
    "\n",
    "# replace critical missing values with their regional averages\n",
    "country_data['NY.GDP.PCAP.KD']=country_data.apply(\n",
    "    lambda x: wdi_country[wdi_country.country=='Latin America & Caribbean']['NY.GDP.PCAP.KD'].iloc[0] if x.country=='Venezuela' else x['NY.GDP.PCAP.KD'],axis=1)\n",
    "country_data['NY.GDP.PCAP.KD']=country_data.apply(\n",
    "    lambda x: wdi_country[wdi_country.country=='Africa Eastern and Southern']['NY.GDP.PCAP.KD'].iloc[0] if x.country=='Eritrea' else x['NY.GDP.PCAP.KD'],axis=1)\n",
    "country_data['NY.GDP.PCAP.KD']=country_data.apply(\n",
    "    lambda x: wdi_country[wdi_country.country=='United Kingdom']['NY.GDP.PCAP.KD'].iloc[0] if x.country=='Gibraltar' else x['NY.GDP.PCAP.KD'],axis=1)\n",
    "\n",
    "country_data['NY.GDP.PCAP.KD']=country_data.apply(\n",
    "    lambda x: wdi_country[wdi_country.country=='East Asia & Pacific']['NY.GDP.PCAP.KD'].iloc[0] if x.country=='Taiwan' else x['NY.GDP.PCAP.KD'],axis=1)    \n",
    "country_data['SP.POP.DPND']=country_data.apply(\n",
    "    lambda x: wdi_country[wdi_country.country=='East Asia & Pacific']['SP.POP.DPND'].iloc[0] if x.country=='Taiwan' else x['SP.POP.DPND'],axis=1)\n",
    "\n",
    "# add gasoline prices\n",
    "fuel=pd.read_csv('data/gasoline_prices_2018.csv')\n",
    "country_data=country_data.set_index('country').join(fuel.set_index('country')).reset_index()\n",
    "\n",
    "# log transform gdp\n",
    "country_data['ln_gdp']=country_data['NY.GDP.PCAP.KD'].apply(lambda x: np.log(x+1))\n",
    "\n",
    "# created dataframe of scaled x-variables\n",
    "country_scaled=pd.DataFrame(preprocessing.scale(country_data[['ln_gdp','SP.POP.DPND','gasoline_2018']]),\n",
    "                       columns=['gdp_standard','dependency_standard','gasoline_standard'],index=country_data.country).join(country_data.set_index('country')[['country_num','ln_gdp','SP.POP.DPND','gasoline_2018']])\n",
    "\n",
    "\n",
    "# add in country-level mode-shares\n",
    "country_shares= dfs['data_'+str(year)[2:]].groupby('country')[['trips_automobile_touse','trips_motorcycle_touse','trips_cycling_touse', 'trips_on_foot_touse','trips_total_touse',\n",
    "                                            'km_on_foot','km_motorcycle','km_automobile','km_cycling','km_total','km_no_transit','population']].sum()\n",
    "for mode in modes_of_transportation:\n",
    "    country_shares[mode+'_share_including_transit'] = country_shares['trips_'+mode+'_touse'] / country_shares.trips_total_touse\n",
    "    country_shares[f'km_share_{mode}'] = country_shares[f'km_{mode}'] / country_shares.km_total\n",
    "    country_shares[f'km_share_{mode}_no_transit'] = country_shares[f'km_{mode}'] / country_shares.km_no_transit\n",
    "cols_to_join = [col for col in country_shares.columns if '_share' in col or 'km_' in col or 'population' in col]\n",
    "country_scaled = country_scaled.join(country_shares[cols_to_join])\n",
    "\n",
    "# calculate km per capita for each mode\n",
    "for col in ['km_on_foot','km_automobile','km_cycling','km_total']:\n",
    "    country_scaled[col+'_pc'] = country_scaled[col] / country_scaled.population.astype(float)\n",
    "\n",
    "# join country data and mode-shares (WITH TRANSIT) to cities\n",
    "dfs['data_'+str(year)[2:]]=dfs['data_'+str(year)[2:]].set_index('country').join(country_scaled[['country_num','gdp_standard', 'dependency_standard', 'gasoline_standard','ln_gdp', 'SP.POP.DPND','gasoline_2018']]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d78e95-fe12-45a3-8e6c-4f7f2331dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in mode-shares INCLUDING TRANSIT to city and country datasets\n",
    "dfs['data_'+str(year)[2:]]['cycling_share_including_transit'] = dfs['data_'+str(year)[2:]].trips_cycling_touse / dfs['data_'+str(year)[2:]].trips_total_touse\n",
    "dfs['data_'+str(year)[2:]]['on_foot_share_including_transit'] = dfs['data_'+str(year)[2:]].trips_on_foot_touse / dfs['data_'+str(year)[2:]].trips_total_touse\n",
    "\n",
    "dfs['data_'+str(year)[2:]] = dfs['data_'+str(year)[2:]].set_index('country')\n",
    "dfs['data_'+str(year)[2:]] = dfs['data_'+str(year)[2:]].join(country_scaled['on_foot_share_including_transit'], rsuffix='_national')\n",
    "dfs['data_'+str(year)[2:]] = dfs['data_'+str(year)[2:]].join(country_scaled['cycling_share_including_transit'], rsuffix='_national')\n",
    "dfs['data_'+str(year)[2:]] = dfs['data_'+str(year)[2:]].join(country_scaled['km_share_on_foot'], rsuffix='_national')\n",
    "dfs['data_'+str(year)[2:]] = dfs['data_'+str(year)[2:]].join(country_scaled['km_share_cycling'], rsuffix='_national')\n",
    "dfs['data_'+str(year)[2:]] = dfs['data_'+str(year)[2:]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b0e3e-ead9-482b-b33e-8424b1c192f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['data_'+str(year)[2:]].to_csv('data/data_'+str(year)[2:]+'.csv')\n",
    "country_scaled.to_csv('data/country_'+str(year)[2:]+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
